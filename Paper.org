#+TITLE: Social Networks and Privacy Models
#+AUTHOR: Clarissa Littler

* Introduction
** The Problem
   Handling privacy and control over content is still an open problem for social media.

   Currently, for any of the major social networks, the more you make full use of social media the more you open yourself up to interactions you don't want: people you don't want to talk to are responding to your words, you're being dragged into conversations you don't want to have, people missing the point with their comments on your work or stripping away attributions from art. 

   Stories of harassment on social media are common place. Not only are conversations regularly, rudely, interrupted but if a post "goes viral" and is quickly spread, then the post's author almost always faces some kind of social consequences. Whether it's several hundred or thousand people not getting the joke and sending variants of the same angry message or it's targeted harassment for an unpopular opinion, the more people who see a post the more potential danger there is for the creator of the post.

   Now, one might be tempted to rebut that these conversations are happening on the public internet and are, thus, fair game for anyone who sees them, but I think that's a rather limiting notion of human interaction. After all, we have expectations of privacy even in offline public places. You don't expect random people to start arguments with you when you're sitting and speaking quietly with a friend, no matter how many people you know or how much social influence you have. 

   I don't think that we should give up our social rules and politeness and respect for each other because it's a new form of communication. In fact, I'd argue the opposite: we need to find better ways to express and enforce how we want to interact with each other. 
   
   Exploring how to do that is going to be the bulk of this note, but first we need to discuss the current state of things.
** Surveying the Field
   For the purpose of this note, we'll be discussing just Facebook, Twitter, and Tumblr as examples of social networks. Not just because these are the ones I'm most familiar with, but also because they're the most popular general-purpose social networks. By general purpose I mean there is a variety of content types and modes of interaction with the site, as opposed to something like Instagram or Vine which is much more special focused on one kind of content and interaction.

   First, we'll discuss the privacy of Facebook. Facebook probably has the most flexible privacy of the three networks we'll be discussing. You can set custom filters on a per-post basis and there's built in tiers of friends, friends-of-friends, and public. In general, though, these filters are about who can *see* a post and there's no distinctions over what types of interactions someone is allowed if they can see the post. Visibility, in a sense, grants all possible permissions on the content.

   Twitter is, by comparison, very very limited in its privacy model. You can block an individual or you can lock down your account so it is only viewable by your followers and you must manually approve requests to follow you. This is a very all-or-nothing idea of privacy: either you are whispering in a private residence or you are making public challenges at a free-for-all debate, neither of which are particularly natural modes of interaction.

   Tumblr is similar to Twitter in this regard. You can make your blog password protected, you can block, and you can make your blog viewable only on someone else's dash and not by directly visiting your blog's URL. Again, these are fairly all-or-nothing approaches to privacy. If someone can see a post then they can interact with it in any possible way.

** An Outline
   For the rest of this note, we'll be addressing one attempt at addressing these issues of privacy in social media. We'll start by layout out, from real life situations, the kinds of expectations of privacy we'd want to have. Then we'll be trying to semi-rigorously lay out all the different forms of interaction we might want to have in social media, teasing apart some separate concepts that I think are conflated in existing systems.

   Then we'll be describing the idea of "permissions" in relation to social media and interaction with content and how fine grained separation of permissions might help improve our networks.

   After that, we'll discuss the notion of capabilities in operating systems and how a concept very much like capabilities can help guide us in understanding how to view privacy on a per-post basis and how to control information flow. 

   Finally, we'll discuss what this hypothetical social network will look like by going through a series of use cases.
* In-person Interactions
  In this section we'll be talking about a number of examples of social interactions that occur in person and discussing the ideas of privacy in interactions that are relevant. I don't intend to classify the gamut of human interaction, but just the ones that seem relevant to our experience of social media. 
** Examples
*** Restaurant
    Imagine being in a restaurant, talking with your friends at your own table. You don't expect anyone to come up to your table and talk to you. You wouldn't expect someone to invite themselves to sit at your table and participate on this time together. 

    By the standards people often use to describe the internet, you should expect those things! After all, you're in public and public means a free-for-all. Of course, that's obviously not true about our in person interactions. In the restaurant example, there's a sense of privacy and expectation that others are excluded from participating. You know full well that people may *listen* to your conversations. I can't really stop my ability to hear all the conversations going on around me in a public place, but I'm never even tempted to invite myself to join in because it's simply understood that that's rude: it violates expectation of privacy.

    In terms of social media, this is the equivalent of being able to witness a conversation but not participate in it. That's a mode of interaction that no current social network can really support. The closest example would be when you can witness Facebook friends commenting on other people's posts from the sidebar. You can't *set* conversations in Facebook to be public-but-exclusive. 
*** Hack night
    Imagine being at a hack night. You're at a venue with large tables and everyone has set up with their laptops and drinks of choice. Nothing organized is happening, just people working on their individual projects and chatting. You're talking with a friend about your newest pet project when someone else at your table perks up and joins the conversation because it's a topic they love too.

    Is that an odd occurence? Would it be unexpected? In this situation, not really. It's expected that other people would want to join in conversations that are relevant to their interests. In the context of a hackathon or the like, part of the goal is to connect with people interested in similar things.
** Social Contracts
   In this section, I won't be presenting any sort of grand philosophic or sociologic thesis, but I want to somewhat informal use the idea of a social contract to discuss why social media interactions play by different rules than in-person social groups.

   I claim that, to at least a first approximation, a kind of social contract binds in-person social groups together. Whether's it's a group of friends or a group of professionals, there's going to be some kind of social rules that you need to obey. If you break them, then the consequences are generally exclusion.

   Everyone has some experience with this, I think. We've all been in that group of friends where one person starts being rude or hostile and, after awhile, they simply start being excluded. This is even true of professional settings: someone who's hostile in a workplace may be fired or a colleague may find that no one wants to work with them on their projects anymore. No matter the scenario, there tend to be at least some kind of consequences for poor behavior, for violating the social contract that holds a group together.
  
   Even in earlier forms of online communication such as message boards, forums, and mailing lists there was still some notion of punishment for acting out: you could be kicked out of the group by an administrator. 

   I argue that in social media, which are by design very distributed and lightweight in their connections between people, there is no effective notion of punishment for poor behavior. You might counter that the admins for the site could enforce punishment, but that's not really true. Kicking people off of Twitter or Facebook or Tumblr only barely addresses the problem. An individual can always make new accounts with new email addresses and variations of their old screen name and beyond that it doesn't take long for someone to reestablish their online presence. Also, the problem of scale, which we'll discuss further, means that accusations of harassment *can't* be investigated thoroughly. I don't have data on this assertion, but it's at the very least my subjective observation that reports of harassment are used at least as often as an offensive weapon as a defensive one, with organized attempts to kick individuals off of the site being itself a form of harassment. 

   Blocking individuals, whether manually or with semi-automated block lists, is also not a real form of punishment. It's easy enough to make more sock-puppet accounts if you really want to harass someone. It's even easier to get as many of your friends who will listen to also harass the target. 
** What Makes Social Media Different?
   Part of the problem with controlling privacy and content on social media is that it is a medium operates very differently than any other form of communication, for several reasons. First, I argue that the very scale is completely unprecedented. No social group or online forum will have millions and tens of millions of members. Thousands, tens of thousands, of people at a time may see tweets in a trending tag. If a celebrity with millions of followers shares your post, suddenly you have that massive spotlight on you for better or worse. Viral tweets can be highlighted on morning news shows and major blogs. It's easy for any individual person to suddenly accrue a massive quantity of attention. 
   
   This scale means that behavior that would be unpleasant, but tolerable, becomes completely overwhelming. If one person misunderstands something you said and "helpfully" corrects you, then it can be annoying but what about when it's suddenly dozens or hundreds of people saying the same thing in a few minutes? If one person decides they don't like you, it's not pleasant but it's a familiar experience we've learned how to deal with since childhood. When you become the enemy of thousands, though, it's like nothing we've experienced before.

(to finish) 
* Separating Permissions
In this section we're going to discuss how permissions generally work in operating systems and how we can apply the idea of permissions to social media in general. We'll be building up to an argument that we need some form of fine grained permissions on posts, much as we'd have for resources such as memory and files in an operating system, rather than the current all-or-nothing approach to interacting with content in your timeline. 
** Permissions in Operating Systems 
   In any operating system, there's a notion of "permissions" on most resources: these permissions determine what entities are allowed to do with these resources, where by entities we mean both users and other programs. 

   The easiest example comes from file systems. If you go into any unix-derived operating system's terminal and type "ls -l" you'll see a detailed list of all the files /and/ the permissions associated with them. There's three different kinds of permission to any file: read, write, and execute. Read and write are fairly straight forward, but execute is a little more subtle. The execute permissions both acts to restrict the ability to run a file as an executable and, in the case of directories, the ability to enter the directory. These permissions also exist in relation to memory in Linux. For example, you can map memory and set its permissions to some combination of read, write, and execute. 
** Permissions in Social Media
   In social media, generally the ability to see a post gives you all forms of access to it. You're able to read the content, obviously, but you're also able to reblog/retweet/share it, comment on it, reply to it, etc. 
   
   This is like if we'd had a file system where the only two permissions were nothing at all or read/write/execute, e.g. if the only two allowed settings for chmod were 000 and 777.

   There are clearly quite a few different /kinds/ of permission that we can imagine in a social network. Among them are things such as

   + The ability to see a post
   + The ability to share a post
   + The ability to share a post with commentary
   + The ability to reply to a post
   + The ability to reply to a post you were tagged in

These are clearly different ways to interact with content, but in general social media sites conflate all of them together. 

It would already be a massive improvement to control over your own content if you could parcel out these permissions as you wanted them. You don't necessarily want everyone who sees a post to be able to share it. You don't necessarily want everyone who can share a post to add their own words onto it [fn:1]. You don't necessarily want people to reply to a post or to enter a conversation that they weren't invited to be part of. 
** Assigning Permissions
   Having separate permissions on content isn't useful unless there's a reasonable way to assign them. For a small closed system you could, albeit tediously, choose what the permissions of each individual user were in relation to each post. Obviously, for a large open system with a variety of users this isn't even possible. There needs to be some criterion for choosing who has what form of access.

   The most obvious approach follows what's called /role based access control/. Role based access control is a concept we're all fairly familiar with in one form or another. When different groups of users on a rdbms have different access to the databases in the system, that's a type of role-based access control. 

   Groups in linux, such as wheel, are another form of role based access control. If you belong to the group you have certain permissions, such as the ability to run the ~su~ and ~sudo~ commands. 

   Even in many workplaces different jobs will come with different software access and ownership over files. 

   Facebook is the social network that comes closest to having a role-based access, with its custom filters on who can see posts. Google+'s circles were even closer, but the platform is now defunct. 

   Facebook, though, still only has an all-or-nothing approach to privacy: if you can see it, you can do anything else with it.

   It wouldn't be hard to imagine, though, a system where you could set up Facebook like groups and then choose what the permissions on your post are for each of these groups by default, with the ability to override your defaults on each individual post. This would, already, be a massive improvement in terms of controlling content than the current state of the art.

   There's still a major problem, though: sharing content, i.e. sharing, retweeting, reblogging. When a post is shared, whose permissions matter? The sharer? The original poster? The least intersection of the two? 

   Let's consider these options in turn. First, if the sharer's permissions are what take primacy then it's too easy to break the web of trust. Let's say that I make a post and I allow you to share it from me. I'm a paranoid person who's nervous about letting people see my, say, elaborate macrame displays [fn:2]. You haven't a macrame care in the world, so you share in a way that completely leaves my post open to the public with all possible permissions intact. This is obviously *not* what I would want.

  Consider instead if it's the original poster's choices that take absolute priority. If this is the case, then the problem happens in reverse. Perhaps I want my post to be seen by everyone and allow them to interact with it in every possible way, but you want to share it and only have a few people see it or ensure that your macrame hating aunt doesn't take this as an opportunity to add a rant to what was a very nice post. 

  What, then, about some kind of intersection of policies or other way to resolve this conflict? The theoretical solution that has a lot of appeal is taking a kind of least-common-denominator of the permissions, a kind of intersection of who-has-what access. This would ensure that neither policy can be violated, but it adds several difficulties: you cannot easily predict what will happen when you share a post. There's no obvious way you can know who of your followers will be able to interact with the post. This is obviously undesireable from a user-interface perspective, but it also complicates our notion of role-based access: suddenly our notion of permissions needs to be attached to the state of the post as it is being shared. We need to more or less trace through the post as it is being passed around, keeping some form of meta-data with it.

  That's not necessarily a bad idea! In fact, it's rather similar to the notion of capabilities in operating system security. If we invert the normal view of permissions on content being relationships between you as a user and other users and, instead, view the permissions as meta-data that belongs on a kind of "pointer" to the content then we can come up with an even more general and novel way to control the flow of information through a social network. 
* Capabilities
Capabilities in operating systems are, essentially, a special pointer to a resource with meta-data attached describing how the resource can be used. There's details about how these capabilities are issued, managed, and made unforgeable that aren't relevant to what we want for social media.

The basic idea is that the resource, be it a file handle or a memory location or another process's ID, comes with a description of what you're allowed to do with it if you have it. If it's a file handle you may be able to read from it, write to it, etc. but *also* there's the question of whether you're able to pass the capability along to another process and even whether you can change its permissions when you do so.

In the context of social media, we can think of your timeline/dash/feed as being the "set" of "pointers" you currently have. If we pair these pointers with a various permissions then we can think of them as being a kind of capability. If you share a post, this is like sharing the pointer with all of your followers. Pushing the analogy further we can expand the notion of permissions attached to a post as consisting of both the old permissions we already discussed

   + The ability to share a post
   + The ability to share a post with commentary
   + The ability to reply to a post
   + The ability to reply to a post you were tagged in

to also include 
   
   + The ability to change the permissions on a post

This ability to change permissions is going to be how we resolve the earlier problem with our role-based access. When a post is shared its permissions will not change unless they have been changed by the sharer, and they can only be changed by the sharer when they themselves have the permission to do so.

There's still an issue of /how/ these capabilities are issued. Capabilities can be issued in accordance with policy but they are not, in and of themselves, policy. For the policy we can appeal to something that looks a lot like the role-based approach above. This time, though, the point of the roles is for how the capabilities are issued when a follower accesses their dash. 

Finally, capabilities in OS security often have the property of being "revokable". There's no reason why we shouldn't also consider posts as revokable. Both Twitter and Tumblr keep track of the tree for who is sharing a post from whom. A user should have the ability to prune the sharing tree at any point when a post has been shared from them, cutting it out of the timelines for all those other users.

I believe this will allow us to better implement the principle of least privilege: that the entities of a system have exactly enough permissions to accomplish the intended policy and no more. In more social media terms, I think this can be restated as: every post should have exactly enough permissions on it to be spread and interacted with as the author intends and no more.
* A Rough Design
In this section I'll be laying out my rough idea for how a social network constructed along these lines would work, with proposed features and examples of usage.
** Features  
Once we accept the idea of permissions as belonging to the post there are a number of other interesting things we can include in terms of privacy and content control.

First, let's imagine that we have a system of tags more akin to Tumblr: the tags are separate data on each sharing of the post. We could include a permission on posts that determines whether or not it can be "obtained" through tag searches. Now, your first thought might be that a post being invisible in tags doesn't have any use, but on Tumblr tags are often used to organize your posts *for yourself*. This could allow us to avoid the problem of having to make up strange new tags in order to simultaneously organize your notes for yourself without necessarily sharing posts in ways you don't want. Tumblr already has the ability to make *all posts* tag unsearchable, but that's the kind of all-or-nothing solution that we're trying to avoid here.

Second, let's go into details on what it might mean to have permission-to-change-permissions. I think a very useful yet simple way to implement it is to have three settings for this permission: the ability to change all permissions on the post, the ability to upgrade permissions to more restrictive, and no ability to change the permissions of the post. The middle setting, the ability to make permissions more restrictive, would be a nice way to make sure that as the content is spread it's settings are /at least/ as restricted as what you've chosen to allow, which helps resolve the conflict we identified above of conflicting privacy policies between different users.

Next, we haven't addressed blocking users til now. I've been assuming that any social network that implemented a notion of privacy like this one would have some kind of strong block feature which would be a complete ban of another user from ever being able to message or interact with . One potentially interesting, though perhaps infeasible, solution would be to keep around an extra bit of data with the capability: the per-post block list. At every point in the sharing tree, the post would "accumulate" the block lists of each person who shares it. The *disadvantage* of this approach is that it means sharing the post through a different chain would be visible to different people. In a sense I'd be willing to accept that "non-commutativity" given that different versions of posts may have different tags or commentary or lead to a different set of users receiving notifications in any case, sharing through different paths in the tree has never led to the exact same post. 

Finally, there are a number of other odd little things that I could see some kind of use for but wouldn't be major features, such as "self-destructing" posts whose permissions change after a certain date or including a limit on a post for how far away from the original it can be shared before its permissions change. 

** Use Cases
Let's consider a few cases that users might find themselves needing and discuss how a system following the rough sketch of features above would be able to implement those privacy policies

First, imagine that you see a post that you want to comment on, perhaps to correct the original poster, but you want to make sure that no one else piles on from your followers. If you downgrade the permissions so it can no longer be shared with additional commentary, then you can safely prevent further attacks.

Next, imagine that you're making an announcement on a serious topic. You want to let your followers know about something but *only* your followers. You can make the post unshareable and unreplyable to all.

(to finish)

* Footnotes

[fn:2] Obviously macrame isn't really something I'd be concerned about, but let's just let it stand for all the things that someone might want to have extra control over: their religion, their sexuality, their politics, their posts about their exes, etc. 

[fn:1] A recent example of this was that I saw someone with many followers share news about a friend's death and then a large number of people piled on in reblogs to interject their own personal politics and turn this /announcement of someone's death/ into a debate. It was probably one of the more infuriatingly inappropriate uses of reblogs that I've seen.
